# 2. 预备知识

## 2.1 数据操作

1. 什么是**张量**
2. 如何**创建**张量、**reshape**张量
3. 怎么**访问**张量的：**shape、元素个数、具体元素、子集**
4. 如何**拼接**张量
5. 举例**广播机制**
6. 张量运算中的**内存机制**，Y = Y + X、Z[:] = Y + X、Y += X 三者的内存上的区别
7. 张量与numpy对象的**转换**

## 2.2 数据预处理

1. os.path.join()、os.mkdirs()、with open as file:
2. pandas包**读取文件**
3. iloc()函数**切片**、fillna()函数**处理 NaN**、get_dummies()函数**字符串转换成类**

## 2.3 线性代数

1. **标量、向量、矩阵**用张量怎么表示
2. 矩阵**装置**函数是什么
3. 矩阵**对应元素相乘**、**矩阵相乘**、**向量内积**、**矩阵向量积**怎么算
4. 向量和矩阵的**一范数、二范数**
5. **sum()、cumsum()、mean()**函数的使用、以及其造成的**降维**的理解

## 2.4 微分

1. **导数、偏导数、梯度**的定义与意义
2. **链式法则**、**正向求值，反向求导**

## 2.5 自动求导

1. 怎么**求梯度**、梯度怎么保存
2. **累计梯度**是什么、怎么**清除累计梯度**
3. 如何**分离**出计算图之外计算
4. **loss**一般为矢量还是标量
5. 如何使用 `sum()` 函数或 `grad_tensors` 实现对向量和矩阵求梯度
