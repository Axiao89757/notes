# 3. 线性神经网络

## 3.1 线性回归

1. 什么是回归？
2. 再问一次，梯度是什么，梯度方向为什么是函数增加最快的方向？

## 3.2 线性回归的从零开始实现

1. 整个过程分成哪些步骤？

   > 1. 生成、读取**数据集**
   > 2. 定义**模型、损失函数、优化算法**
   > 3. **训练**
   
2. 数据集如何生成？

3. 数据集如何读取？**迭代器**作用、意义是什么？迭代器怎么实现？

4. **模型**如何定义？输入是哪些？输出是什么？

5. **损失函数**如何定义？输入是什么？输出是什么？

6. **优化算法**如何定义？输入是什么？输出是什么？作用是什么？

7. **训练步骤**是怎样的？

   > 1. 设定 epoch 的次数，即：**模型要训练多少回**。
   > 2. 在**一次 epoch 里**：
   >    1. 从数据集迭代器中取 *数据*
   >    2. 计算模型 *输出值*
   >    3. 计算模型 *误差值*
   >    4. 计算模型误差的 *梯度*
   >    5. 运用优化算法 *更新模型参数*
   > 3. 计算一次**平均误差**。

   ```python
   # 核心代码
   # 1. 循环训练epoch次
   for epoch in range(num_epoches):
       # 2. 每一次取出 batch_size 个样本除了，做一次计算
       for X, y in data_iter(batch_size, features, labels):
           # 2.1 计算模型输出值，计算模型损失函数
           l = loss(net(X, w, b), y)
           # 2.2 反向传播，即计算各个参数的偏导数
           l.sum().backward()
           # 2.3 更新各个参数
           sgd([w, b], lr, batch_size)
       # 3. 计算平均误差
       with torch.no_grad():
           train_l = loss(net(features, w, b), labels)
           print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')
   ```

   

   